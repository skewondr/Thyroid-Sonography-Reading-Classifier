{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (Basic) LSTM & Pre-trained GloVe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6, 2], [3, 1], [7, 4], [8, 1], [9], [10], [5, 4], [11, 3], [5, 1], [12, 13, 2, 14]]\n",
      "[[ 6  2  0  0]\n",
      " [ 3  1  0  0]\n",
      " [ 7  4  0  0]\n",
      " [ 8  1  0  0]\n",
      " [ 9  0  0  0]\n",
      " [10  0  0  0]\n",
      " [ 5  4  0  0]\n",
      " [11  3  0  0]\n",
      " [ 5  1  0  0]\n",
      " [12 13  2 14]]\n",
      "Loaded 400000 word vectors.\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 4, 100)            1500      \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 400)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 401       \n",
      "=================================================================\n",
      "Total params: 1,901\n",
      "Trainable params: 401\n",
      "Non-trainable params: 1,500\n",
      "_________________________________________________________________\n",
      "None\n",
      "Accuracy: 100.000000\n"
     ]
    }
   ],
   "source": [
    "from numpy import array\n",
    "from numpy import asarray\n",
    "from numpy import zeros\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Embedding\n",
    "# define documents\n",
    "docs = ['Well done!',\n",
    "\t\t'Good work',\n",
    "\t\t'Great effort',\n",
    "\t\t'nice work',\n",
    "\t\t'Excellent!',\n",
    "\t\t'Weak',\n",
    "\t\t'Poor effort!',\n",
    "\t\t'not good',\n",
    "\t\t'poor work',\n",
    "\t\t'Could have done better.']\n",
    "# define class labels\n",
    "labels = array([1,1,1,1,1,0,0,0,0,0])\n",
    "# prepare tokenizer\n",
    "t = Tokenizer()\n",
    "t.fit_on_texts(docs)\n",
    "vocab_size = len(t.word_index) + 1\n",
    "# integer encode the documents\n",
    "encoded_docs = t.texts_to_sequences(docs)\n",
    "print(encoded_docs)\n",
    "# pad documents to a max length of 4 words\n",
    "max_length = 4\n",
    "padded_docs = pad_sequences(encoded_docs, maxlen=max_length, padding='post')\n",
    "print(padded_docs)\n",
    "# load the whole embedding into memory\n",
    "embeddings_index = dict()\n",
    "f = open('../data/glove.6B.100d.txt')\n",
    "for line in f:\n",
    "\tvalues = line.split()\n",
    "\tword = values[0]\n",
    "\tcoefs = asarray(values[1:], dtype='float32')\n",
    "\tembeddings_index[word] = coefs\n",
    "f.close()\n",
    "print('Loaded %s word vectors.' % len(embeddings_index))\n",
    "# create a weight matrix for words in training docs\n",
    "embedding_matrix = zeros((vocab_size, 100))\n",
    "for word, i in t.word_index.items():\n",
    "\tembedding_vector = embeddings_index.get(word)\n",
    "\tif embedding_vector is not None:\n",
    "\t\tembedding_matrix[i] = embedding_vector\n",
    "# define model\n",
    "model = Sequential()\n",
    "e = Embedding(vocab_size, 100, weights=[embedding_matrix], input_length=4, trainable=False)\n",
    "model.add(e)\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "# compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "# summarize the model\n",
    "print(model.summary())\n",
    "# fit the model\n",
    "model.fit(padded_docs, labels, epochs=50, verbose=0)\n",
    "# evaluate the model\n",
    "loss, accuracy = model.evaluate(padded_docs, labels, verbose=0)\n",
    "print('Accuracy: %f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM학습. GLOVE임베딩을 사용한다. \n",
    "### tokenize: use split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import read_vocab, count_parameters, load_glove\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import nltk\n",
    "import itertools\n",
    "import pickle\n",
    "\n",
    "def read_files(data_dir, type_):\n",
    "    train = pd.read_csv(data_dir+type_+'train.tsv', sep='\\t')\n",
    "    dev = pd.read_csv(data_dir+type_+'dev.tsv', sep='\\t')\n",
    "    test = pd.read_csv(data_dir+type_+'test.tsv', sep='\\t')\n",
    "    return train, dev, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def w2seq(vocab, doc):\n",
    "    max_len=100\n",
    "    mapped_doc = pd.DataFrame()\n",
    "    for sent in doc['text']:\n",
    "        \n",
    "        sample = [vocab.get(word, 1) for word in sent.split()]\n",
    "        #zero padding \n",
    "        sample = np.pad(sample, (max_len-len(sample),0), mode='constant')\n",
    "        \n",
    "#         for word in sent.split():\n",
    "#             if vocab.get(word, 1) == 1: print(word, \" is not in corpus.\")    \n",
    "        \n",
    "        Dict = dict.fromkeys(range(100),0)\n",
    "        for i in range(max_len):\n",
    "            Dict[i] = sample[i]\n",
    "        mapped_doc = mapped_doc.append(Dict, ignore_index = True)\n",
    "#     print(mapped_doc)\n",
    "    mapped_doc['label'] = doc['label']\n",
    "    return mapped_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.datasets import reuters\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Dense, LSTM, Embedding, Dropout\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from tensorflow.python.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.python.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.python.keras.models import load_model\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.python.keras.models import load_model\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from numpy import zeros\n",
    "from tensorflow import keras\n",
    "from keras.optimizers import SGD, Adam \n",
    "#https://machinelearningmastery.com/use-word-embedding-layers-deep-learning-keras/\n",
    "\n",
    "def train_model(train, dev, vocab, data_dir, result_dir, type_):\n",
    "    \n",
    "    #default emb_size: 200\n",
    "    max_length = 100\n",
    "    n_classes = 3\n",
    "    emb_size = 200\n",
    "    batch_size = 10\n",
    "    epoch_size = 80\n",
    "     #return embedding matrix dictionary.\n",
    "    glove_embs = load_glove(data_dir+'glove.6B.{}d.txt'.format(emb_size), emb_size, vocab)\n",
    "    #print(glove_embs)\n",
    "    \n",
    "    es = EarlyStopping(monitor='val_loss', mode='min', verbose=0, patience=10)\n",
    "    mc = ModelCheckpoint(result_dir+type_+'lstm_model.h5', monitor='val_acc',mode='max', \n",
    "                     verbose=0, save_best_only=True)\n",
    "\n",
    "    with tf.device('/CPU:0'):\n",
    "\n",
    "        model = Sequential()\n",
    "        #Embedding(number of samples(단어 사전 크기), hidden layer size)\n",
    "        e = Embedding(len(vocab), emb_size, weights=[glove_embs], input_length=max_length, trainable=False)\n",
    "        model.add(e) \n",
    "        #batch norm. 의미 없음. activation func.이 tanh라서 output 값이 이미 정규화 됨. \n",
    "        #lstm 에서는 relu를 사용하지 않는다. 데이터나 모델에 부적절함. 큰값의 출력이 시계열 데이터의 변동성을 크게 한다. \n",
    "        model.add(LSTM(emb_size, return_sequences=True))\n",
    "        model.add(Dropout(0.3))\n",
    "        model.add(LSTM(emb_size, return_sequences=True))\n",
    "        model.add(Dropout(0.3))\n",
    "        model.add(LSTM(emb_size))\n",
    "        model.add(Dense(n_classes, activation='softmax'))\n",
    "        \n",
    "        #initial_learning_rate * decay_rate ^ (step / decay_steps)\n",
    "#         lr_schedule = keras.optimizers.schedules.ExponentialDecay(initial_learning_rate=3e-4, \n",
    "#                                                               decay_steps=100, decay_rate=0.4)\n",
    "#         #default : learning_rate=0.001\n",
    "#         opt = keras.optimizers.Adam(learning_rate=lr_schedule)\n",
    "        opt = Adam(learning_rate=3e-4)\n",
    "        model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['acc'])\n",
    "        model.summary()\n",
    "        \n",
    "        [print(i.shape, i.dtype) for i in model.inputs]\n",
    "        [print(o.shape, o.dtype) for o in model.outputs]\n",
    "        [print(l.name, l.input_shape, l.dtype) for l in model.layers]\n",
    "#         print(train, to_categorical(train_['label'], num_classes=n_classes))\n",
    "#         print(dev, to_categorical(dev_['label'], num_classes=n_classes))\n",
    "        history = model.fit(train.iloc[:,:-1], to_categorical(train['label'], num_classes=n_classes), batch_size=batch_size, epochs=epoch_size, \n",
    "                            verbose=1, callbacks=[es, mc], \n",
    "                            validation_data=(dev.iloc[:,:-1], to_categorical(dev['label'], num_classes=n_classes)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model2(train, dev, vocab, data_dir, result_dir, type_):\n",
    "      \n",
    "    es = EarlyStopping(monitor='val_loss', mode='min', verbose=0, patience=10)\n",
    "    mc = ModelCheckpoint(result_dir+type_+'lstm_model.h5', monitor='val_acc',mode='max', \n",
    "                     verbose=0, save_best_only=True)\n",
    "\n",
    "    \n",
    "    with tf.device('/CPU:0'):\n",
    "        hidden=100\n",
    "\n",
    "        model = Sequential()\n",
    "        #Embedding(number of samples(단어 사전 크기), hidden layer size)\n",
    "        model.add(Embedding(len(vocab), hidden))\n",
    "        model.add(LSTM(hidden, return_sequences=True))\n",
    "        model.add(Dropout(0.3))\n",
    "        model.add(LSTM(hidden, return_sequences=True))\n",
    "        model.add(Dropout(0.3))\n",
    "        model.add(LSTM(hidden))\n",
    "        model.add(Dense(3, activation='softmax'))\n",
    "        opt = Adam(learning_rate=3e-4)\n",
    "        model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['acc'])\n",
    "        history = model.fit(train.iloc[:,:-1], to_categorical(train['label'], num_classes=3), batch_size=10, epochs=80, \n",
    "                            verbose=1, callbacks=[es, mc], \n",
    "                            validation_data=(dev.iloc[:,:-1],to_categorical(dev['label'], num_classes=3)))\n",
    "        model.summary()\n",
    "        #scores = model.evaluate(X[val], to_categorical(Y[val], num_classes=3), verbose=0)\n",
    "        #print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "        #cvscores.append(scores[1] * 100)\n",
    "        #model.save_weights('check_points/val'+str(num))\n",
    "\n",
    "    #print(\"%.2f%% (+/- %.2f%%)\" % (np.mean(cvscores), np.std(cvscores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'seaborn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-363ed30da7cd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mclassification_report\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtest_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'seaborn'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sn\n",
    "\n",
    "def test_result(title, test, result_dir, type_):\n",
    "    re_model = load_model(result_dir+type_+'lstm_model.h5')\n",
    "    y_pred = re_model.predict_classes(test.iloc[:,:-1])\n",
    "\n",
    "    target_names=['0', '1', '2']\n",
    "    print(\"Accuracy:\", metrics.accuracy_score(test['label'], y_pred))\n",
    "    print(classification_report(test['label'], y_pred, target_names=target_names))\n",
    "\n",
    "    data_= {'y_Actual': test['label'], 'y_Predicted': y_pred}\n",
    "    df_cm = pd.DataFrame(data_, columns=['y_Actual','y_Predicted'])\n",
    "    confusion_matrix = pd.crosstab(df_cm['y_Actual'], df_cm['y_Predicted'],\n",
    "                                   rownames=['Actual'], colnames=['Predicted'])\n",
    "\n",
    "    sn.heatmap(confusion_matrix, annot=True)\n",
    "    plt.savefig(title+'cm.png', box_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(data_dir, result_dir, type_):\n",
    "    train_, dev_, test_ = read_files(data_dir, type_)\n",
    "    print(\"train sample: \", train_.shape[0])\n",
    "    #print(train_)\n",
    "    \n",
    "    #TFIDF 이후 w2i.pkl파일 생성된 상태.\n",
    "    vocab = read_vocab(data_dir+ type_+'w2i.pkl') #return word_to_index dictionary.\n",
    "    train = w2seq(vocab, train_ )\n",
    "    dev = w2seq(vocab, dev_ )\n",
    "    test = w2seq(vocab, test_)\n",
    "    \n",
    "    train_model(train, dev, vocab, data_dir, result_dir, type_)\n",
    "    \n",
    "    title = result_dir+type_\n",
    "    test_result(title, test, result_dir, type_ )\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"../data/\"\n",
    "result_dir = \"./lstm_result/\"\n",
    "type_ = ['uneven-even/', 'even-even/', 'upeven-even/']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train sample:  1196\n",
      "Loading vocabulary ...\n",
      "Vocabulary size = 1527\n",
      "Loading Glove pre-trained word embeddings ...\n",
      "Total 400000 word vectors in ../data/glove.6B.200d.txt\n",
      "Number of OOV words = 730\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 100, 200)          305400    \n",
      "_________________________________________________________________\n",
      "lstm_6 (LSTM)                (None, 100, 200)          320800    \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 100, 200)          0         \n",
      "_________________________________________________________________\n",
      "lstm_7 (LSTM)                (None, 100, 200)          320800    \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 100, 200)          0         \n",
      "_________________________________________________________________\n",
      "lstm_8 (LSTM)                (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 3)                 603       \n",
      "=================================================================\n",
      "Total params: 1,268,403\n",
      "Trainable params: 963,003\n",
      "Non-trainable params: 305,400\n",
      "_________________________________________________________________\n",
      "(None, 100) <dtype: 'float32'>\n",
      "(None, 3) <dtype: 'float32'>\n",
      "embedding_2 (None, 100) float32\n",
      "lstm_6 (None, 100, 200) float32\n",
      "dropout_4 (None, 100, 200) float32\n",
      "lstm_7 (None, 100, 200) float32\n",
      "dropout_5 (None, 100, 200) float32\n",
      "lstm_8 (None, 100, 200) float32\n",
      "dense_2 (None, 200) float32\n",
      "Epoch 1/80\n",
      "120/120 [==============================] - 30s 252ms/step - loss: 0.6060 - acc: 0.7977 - val_loss: 1.1821 - val_acc: 0.3333\n",
      "Epoch 2/80\n",
      " 51/120 [===========>..................] - ETA: 17s - loss: 0.4895 - acc: 0.8039"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-53bdbd53d556>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-6-f4e94970bc40>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(data_dir, result_dir, type_)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mw2seq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdev\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mtitle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult_dir\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mtype_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-34ed68be9e43>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(train, dev, vocab, data_dir, result_dir, type_)\u001b[0m\n\u001b[1;32m     63\u001b[0m         history = model.fit(train.iloc[:,:-1], to_categorical(train['label'], num_classes=n_classes), batch_size=batch_size, epochs=epoch_size, \n\u001b[1;32m     64\u001b[0m                             \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m                             validation_data=(dev.iloc[:,:-1], to_categorical(dev['label'], num_classes=n_classes)))\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/medinfo2/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/medinfo2/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/medinfo2/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/medinfo2/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    805\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/medinfo2/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/medinfo2/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[1;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/medinfo2/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1924\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/medinfo2/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/anaconda3/envs/medinfo2/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "main(data_dir, result_dir, type_[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train sample:  1196\n",
      "Loading vocabulary ...\n",
      "Vocabulary size = 1527\n",
      "Loading Glove pre-trained word embeddings ...\n",
      "Total 400000 word vectors in ../data/glove.6B.200d.txt\n",
      "Number of OOV words = 730\n",
      "(None, 100) <dtype: 'float32'>\n",
      "(None, 3) <dtype: 'float32'>\n",
      "embedding_23 (None, 100) float32\n",
      "lstm_64 (None, 100, 200) float32\n",
      "dropout_42 (None, 100, 200) float32\n",
      "lstm_65 (None, 100, 200) float32\n",
      "dropout_43 (None, 100, 200) float32\n",
      "lstm_66 (None, 100, 200) float32\n",
      "dense_23 (None, 200) float32\n",
      "Epoch 1/80\n",
      "120/120 [==============================] - 29s 242ms/step - loss: 0.6070 - acc: 0.7952 - val_loss: 1.3134 - val_acc: 0.3611\n",
      "Epoch 2/80\n",
      "120/120 [==============================] - 31s 258ms/step - loss: 0.4624 - acc: 0.8202 - val_loss: 1.0036 - val_acc: 0.5278\n",
      "Epoch 3/80\n",
      "120/120 [==============================] - 30s 250ms/step - loss: 0.4327 - acc: 0.8278 - val_loss: 1.1082 - val_acc: 0.4444\n",
      "Epoch 4/80\n",
      "120/120 [==============================] - 30s 250ms/step - loss: 0.3413 - acc: 0.8763 - val_loss: 0.7556 - val_acc: 0.6667\n",
      "Epoch 5/80\n",
      "120/120 [==============================] - 30s 251ms/step - loss: 0.2847 - acc: 0.8855 - val_loss: 1.3176 - val_acc: 0.5556\n",
      "Epoch 6/80\n",
      "120/120 [==============================] - 31s 255ms/step - loss: 0.2736 - acc: 0.9022 - val_loss: 0.9490 - val_acc: 0.6944\n",
      "Epoch 7/80\n",
      "120/120 [==============================] - 31s 260ms/step - loss: 0.2281 - acc: 0.9055 - val_loss: 1.1582 - val_acc: 0.6667\n",
      "Epoch 8/80\n",
      "120/120 [==============================] - 30s 252ms/step - loss: 0.2125 - acc: 0.9206 - val_loss: 0.8071 - val_acc: 0.7222\n",
      "Epoch 9/80\n",
      "120/120 [==============================] - 30s 250ms/step - loss: 0.1872 - acc: 0.9331 - val_loss: 0.6220 - val_acc: 0.7778\n",
      "Epoch 10/80\n",
      "120/120 [==============================] - 30s 250ms/step - loss: 0.1514 - acc: 0.9440 - val_loss: 0.9555 - val_acc: 0.7500\n",
      "Epoch 11/80\n",
      "120/120 [==============================] - 30s 250ms/step - loss: 0.1306 - acc: 0.9523 - val_loss: 1.2050 - val_acc: 0.7222\n",
      "Epoch 12/80\n",
      "120/120 [==============================] - 30s 249ms/step - loss: 0.1593 - acc: 0.9406 - val_loss: 0.7099 - val_acc: 0.8333\n",
      "Epoch 13/80\n",
      "120/120 [==============================] - 30s 248ms/step - loss: 0.1121 - acc: 0.9615 - val_loss: 1.0601 - val_acc: 0.6944\n",
      "Epoch 14/80\n",
      "120/120 [==============================] - 30s 248ms/step - loss: 0.0768 - acc: 0.9758 - val_loss: 0.8927 - val_acc: 0.8056\n",
      "Epoch 15/80\n",
      "120/120 [==============================] - 30s 249ms/step - loss: 0.1007 - acc: 0.9666 - val_loss: 1.1944 - val_acc: 0.7222\n",
      "Epoch 16/80\n",
      "120/120 [==============================] - 30s 250ms/step - loss: 0.0674 - acc: 0.9824 - val_loss: 1.2484 - val_acc: 0.7222\n",
      "Epoch 17/80\n",
      "120/120 [==============================] - 30s 250ms/step - loss: 0.0795 - acc: 0.9749 - val_loss: 1.3772 - val_acc: 0.6944\n",
      "Epoch 18/80\n",
      "120/120 [==============================] - 31s 260ms/step - loss: 0.0370 - acc: 0.9866 - val_loss: 1.5970 - val_acc: 0.7222\n",
      "Epoch 19/80\n",
      "120/120 [==============================] - 30s 253ms/step - loss: 0.0477 - acc: 0.9841 - val_loss: 1.6969 - val_acc: 0.7222\n",
      "WARNING:tensorflow:Layer lstm_64 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_65 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_66 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f88acf3e050> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Accuracy: 0.72\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.96      0.76        25\n",
      "           1       0.80      0.48      0.60        25\n",
      "           2       0.82      0.72      0.77        25\n",
      "\n",
      "    accuracy                           0.72        75\n",
      "   macro avg       0.75      0.72      0.71        75\n",
      "weighted avg       0.75      0.72      0.71        75\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yoonjin/anaconda3/envs/medinfo/lib/python3.7/site-packages/ipykernel_launcher.py:21: MatplotlibDeprecationWarning: savefig() got unexpected keyword argument \"box_inches\" which is no longer supported as of 3.3 and will become an error two minor releases later\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "main(data_dir, result_dir, type_[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train sample:  270\n",
      "Loading vocabulary ...\n",
      "Vocabulary size = 994\n",
      "Loading Glove pre-trained word embeddings ...\n",
      "Total 400000 word vectors in ../data/glove.6B.200d.txt\n",
      "Number of OOV words = 424\n",
      "(None, 100) <dtype: 'float32'>\n",
      "(None, 3) <dtype: 'float32'>\n",
      "embedding_19 (None, 100) float32\n",
      "lstm_52 (None, 100, 200) float32\n",
      "dropout_34 (None, 100, 200) float32\n",
      "lstm_53 (None, 100, 200) float32\n",
      "dropout_35 (None, 100, 200) float32\n",
      "lstm_54 (None, 100, 200) float32\n",
      "dense_19 (None, 200) float32\n",
      "Epoch 1/80\n",
      "27/27 [==============================] - 6s 237ms/step - loss: 1.0934 - acc: 0.3926 - val_loss: 1.0388 - val_acc: 0.6111\n",
      "Epoch 2/80\n",
      "27/27 [==============================] - 6s 219ms/step - loss: 0.9957 - acc: 0.5704 - val_loss: 0.8890 - val_acc: 0.5556\n",
      "Epoch 3/80\n",
      "27/27 [==============================] - 6s 221ms/step - loss: 0.8440 - acc: 0.6259 - val_loss: 0.7842 - val_acc: 0.6667\n",
      "Epoch 4/80\n",
      "27/27 [==============================] - 6s 220ms/step - loss: 0.6945 - acc: 0.7074 - val_loss: 0.7166 - val_acc: 0.6667\n",
      "Epoch 5/80\n",
      "27/27 [==============================] - 6s 220ms/step - loss: 0.5813 - acc: 0.7444 - val_loss: 0.7099 - val_acc: 0.7222\n",
      "Epoch 6/80\n",
      "27/27 [==============================] - 6s 221ms/step - loss: 0.5288 - acc: 0.7852 - val_loss: 0.7183 - val_acc: 0.7778\n",
      "Epoch 7/80\n",
      "27/27 [==============================] - 6s 218ms/step - loss: 0.5205 - acc: 0.7741 - val_loss: 0.6858 - val_acc: 0.7500\n",
      "Epoch 8/80\n",
      "27/27 [==============================] - 6s 218ms/step - loss: 0.3952 - acc: 0.8519 - val_loss: 0.8060 - val_acc: 0.7222\n",
      "Epoch 9/80\n",
      "27/27 [==============================] - 6s 218ms/step - loss: 0.3425 - acc: 0.8778 - val_loss: 0.6011 - val_acc: 0.7778\n",
      "Epoch 10/80\n",
      "27/27 [==============================] - 6s 222ms/step - loss: 0.2750 - acc: 0.8963 - val_loss: 0.8164 - val_acc: 0.8056\n",
      "Epoch 11/80\n",
      "27/27 [==============================] - 6s 220ms/step - loss: 0.2602 - acc: 0.9111 - val_loss: 0.7202 - val_acc: 0.8056\n",
      "Epoch 12/80\n",
      "27/27 [==============================] - 6s 219ms/step - loss: 0.1857 - acc: 0.9370 - val_loss: 1.0764 - val_acc: 0.6667\n",
      "Epoch 13/80\n",
      "27/27 [==============================] - 6s 219ms/step - loss: 0.1272 - acc: 0.9593 - val_loss: 0.9128 - val_acc: 0.7222\n",
      "Epoch 14/80\n",
      "27/27 [==============================] - 6s 218ms/step - loss: 0.1381 - acc: 0.9481 - val_loss: 0.9905 - val_acc: 0.7500\n",
      "Epoch 15/80\n",
      "27/27 [==============================] - 6s 223ms/step - loss: 0.1446 - acc: 0.9481 - val_loss: 1.1442 - val_acc: 0.6944\n",
      "Epoch 16/80\n",
      "27/27 [==============================] - 6s 218ms/step - loss: 0.1424 - acc: 0.9519 - val_loss: 0.9595 - val_acc: 0.7222\n",
      "Epoch 17/80\n",
      "27/27 [==============================] - 6s 218ms/step - loss: 0.0935 - acc: 0.9704 - val_loss: 0.9989 - val_acc: 0.7222\n",
      "Epoch 18/80\n",
      "27/27 [==============================] - 6s 220ms/step - loss: 0.0402 - acc: 0.9926 - val_loss: 1.0348 - val_acc: 0.6667\n",
      "Epoch 19/80\n",
      "27/27 [==============================] - 6s 221ms/step - loss: 0.0286 - acc: 0.9963 - val_loss: 1.1650 - val_acc: 0.7222\n",
      "WARNING:tensorflow:Layer lstm_52 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_53 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_54 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f88ac1deb90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Accuracy: 0.68\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.68      0.74        25\n",
      "           1       0.54      0.60      0.57        25\n",
      "           2       0.73      0.76      0.75        25\n",
      "\n",
      "    accuracy                           0.68        75\n",
      "   macro avg       0.69      0.68      0.68        75\n",
      "weighted avg       0.69      0.68      0.68        75\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yoonjin/anaconda3/envs/medinfo/lib/python3.7/site-packages/ipykernel_launcher.py:21: MatplotlibDeprecationWarning: savefig() got unexpected keyword argument \"box_inches\" which is no longer supported as of 3.3 and will become an error two minor releases later\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "main(data_dir, result_dir, type_[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train sample:  435\n",
      "Loading vocabulary ...\n",
      "Vocabulary size = 1091\n",
      "Loading Glove pre-trained word embeddings ...\n",
      "Total 400000 word vectors in ../data/glove.6B.200d.txt\n",
      "Number of OOV words = 473\n",
      "(None, 100) <dtype: 'float32'>\n",
      "(None, 3) <dtype: 'float32'>\n",
      "embedding_20 (None, 100) float32\n",
      "lstm_55 (None, 100, 200) float32\n",
      "dropout_36 (None, 100, 200) float32\n",
      "lstm_56 (None, 100, 200) float32\n",
      "dropout_37 (None, 100, 200) float32\n",
      "lstm_57 (None, 100, 200) float32\n",
      "dense_20 (None, 200) float32\n",
      "Epoch 1/80\n",
      "44/44 [==============================] - 11s 258ms/step - loss: 1.0702 - acc: 0.4414 - val_loss: 0.9614 - val_acc: 0.5833\n",
      "Epoch 2/80\n",
      "44/44 [==============================] - 11s 250ms/step - loss: 0.8625 - acc: 0.5816 - val_loss: 0.8194 - val_acc: 0.6389\n",
      "Epoch 3/80\n",
      "44/44 [==============================] - 11s 247ms/step - loss: 0.6787 - acc: 0.7034 - val_loss: 0.7023 - val_acc: 0.6944\n",
      "Epoch 4/80\n",
      "44/44 [==============================] - 11s 249ms/step - loss: 0.5858 - acc: 0.7586 - val_loss: 0.7652 - val_acc: 0.7778\n",
      "Epoch 5/80\n",
      "44/44 [==============================] - 11s 248ms/step - loss: 0.4783 - acc: 0.8138 - val_loss: 0.7304 - val_acc: 0.8056\n",
      "Epoch 6/80\n",
      "44/44 [==============================] - 11s 247ms/step - loss: 0.4364 - acc: 0.8230 - val_loss: 0.8711 - val_acc: 0.7778\n",
      "Epoch 7/80\n",
      "44/44 [==============================] - 11s 247ms/step - loss: 0.4017 - acc: 0.8529 - val_loss: 0.8587 - val_acc: 0.7778\n",
      "Epoch 8/80\n",
      "44/44 [==============================] - 11s 248ms/step - loss: 0.4248 - acc: 0.8322 - val_loss: 0.8403 - val_acc: 0.7778\n",
      "Epoch 9/80\n",
      "44/44 [==============================] - 11s 248ms/step - loss: 0.3024 - acc: 0.8897 - val_loss: 0.9471 - val_acc: 0.7778\n",
      "Epoch 10/80\n",
      "44/44 [==============================] - 11s 247ms/step - loss: 0.2546 - acc: 0.8920 - val_loss: 0.9047 - val_acc: 0.7778\n",
      "Epoch 11/80\n",
      "44/44 [==============================] - 11s 247ms/step - loss: 0.2864 - acc: 0.8943 - val_loss: 0.9506 - val_acc: 0.7500\n",
      "Epoch 12/80\n",
      "44/44 [==============================] - 11s 251ms/step - loss: 0.1616 - acc: 0.9333 - val_loss: 1.0609 - val_acc: 0.7500\n",
      "Epoch 13/80\n",
      "44/44 [==============================] - 11s 251ms/step - loss: 0.2038 - acc: 0.9195 - val_loss: 0.9631 - val_acc: 0.7778\n",
      "WARNING:tensorflow:Layer lstm_55 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_56 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_57 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f88ac325560> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Accuracy: 0.64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.52      0.60        25\n",
      "           1       0.55      0.68      0.61        25\n",
      "           2       0.69      0.72      0.71        25\n",
      "\n",
      "    accuracy                           0.64        75\n",
      "   macro avg       0.65      0.64      0.64        75\n",
      "weighted avg       0.65      0.64      0.64        75\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yoonjin/anaconda3/envs/medinfo/lib/python3.7/site-packages/ipykernel_launcher.py:21: MatplotlibDeprecationWarning: savefig() got unexpected keyword argument \"box_inches\" which is no longer supported as of 3.3 and will become an error two minor releases later\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "main(data_dir, result_dir, type_[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "medinfo2",
   "language": "python",
   "name": "medinfo2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
